{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "82f59b54",
      "metadata": {
        "id": "82f59b54",
        "outputId": "c25cbda8-889f-4f40-c004-067df9622af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: peft 0.18.0\n",
            "Uninstalling peft-0.18.0:\n",
            "  Successfully uninstalled peft-0.18.0\n",
            "Found existing installation: accelerate 1.12.0\n",
            "Uninstalling accelerate-1.12.0:\n",
            "  Successfully uninstalled accelerate-1.12.0\n",
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m560.1/560.1 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 9.5.0 requires sqlglot<25.21,>=23.4, but you have sqlglot 28.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ TRL version: 0.27.0.dev0\n",
            "✅ GRPOTrainer imported successfully!\n",
            "✅ GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/trl.git\n",
        "!pip install -q -U transformers accelerate peft datasets bitsandbytes sqlglot\n",
        "\n",
        "import torch\n",
        "import trl\n",
        "from trl import GRPOTrainer, GRPOConfig\n",
        "\n",
        "print(f\"✅ TRL version: {trl.__version__}\")\n",
        "print(f\"✅ GRPOTrainer imported successfully!\")\n",
        "print(f\"✅ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU found'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "113c0131",
      "metadata": {
        "id": "113c0131",
        "outputId": "2d07ea1a-b3f5-435b-f0eb-e3d5279c395d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 24.9M  100 24.9M    0     0  15.9M      0  0:00:01  0:00:01 --:--:-- 44.2M\n"
          ]
        }
      ],
      "source": [
        "! curl -L -o data.tar.bz2 https://github.com/salesforce/WikiSQL/raw/master/data.tar.bz2\n",
        "! tar -xjf data.tar.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4a8e4011",
      "metadata": {
        "id": "4a8e4011"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sqlglot\n",
        "import pandas as pd\n",
        "from datasets import Dataset, Features, Value, Sequence\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from trl import GRPOTrainer, GRPOConfig\n",
        "from peft import LoraConfig\n",
        "import json\n",
        "import sqlglot\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "MODEL_NAME = \"ibm-granite/granite-4.0-350m-base\"\n",
        "OUTPUT_DIR = \"/granite-grpo-wikisql\"\n",
        "MAX_PROMPT_LENGTH = 512\n",
        "MAX_COMPLETION_LENGTH = 128\n",
        "LOCAL_DATA_DIR = \"data\"\n",
        "\n",
        "# Feature Schema\n",
        "WIKISQL_FEATURES = Features({\n",
        "    \"phase\": Value(\"int32\"),\n",
        "    \"question\": Value(\"string\"),\n",
        "    \"sql\": Value(\"string\"),\n",
        "    \"table\": Value(\"string\"),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "eba09407",
      "metadata": {
        "id": "eba09407",
        "outputId": "da779b75-2c1e-45cb-ac04-c37807ce748e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading and preparation complete. Training subset size: 2000\n",
            "First example:\n",
            "{'phase': 1, 'question': 'Tell me what the notes are for South Australia ', 'sql': '{\"sel\": 5, \"conds\": [[3, 0, \"SOUTH AUSTRALIA\"]], \"agg\": 0}', 'table': '{\"header\": [\"State/territory\", \"Text/background colour\", \"Format\", \"Current slogan\", \"Current series\", \"Notes\"], \"types\": [\"text\", \"text\", \"text\", \"text\", \"text\", \"text\"], \"rows\": [[\"Australian Capital Territory\", \"blue/white\", \"Yaa\\\\u00b7nna\", \"ACT \\\\u00b7 CELEBRATION OF A CENTURY 2013\", \"YIL\\\\u00b700A\", \"Slogan screenprinted on plate\"], [\"New South Wales\", \"black/yellow\", \"aa\\\\u00b7nn\\\\u00b7aa\", \"NEW SOUTH WALES\", \"BX\\\\u00b799\\\\u00b7HI\", \"No slogan on current series\"], [\"New South Wales\", \"black/white\", \"aaa\\\\u00b7nna\", \"NSW\", \"CPX\\\\u00b712A\", \"Optional white slimline series\"], [\"Northern Territory\", \"ochre/white\", \"Ca\\\\u00b7nn\\\\u00b7aa\", \"NT \\\\u00b7 OUTBACK AUSTRALIA\", \"CB\\\\u00b706\\\\u00b7ZZ\", \"New series began in June 2011\"], [\"Queensland\", \"maroon/white\", \"nnn\\\\u00b7aaa\", \"QUEENSLAND \\\\u00b7 SUNSHINE STATE\", \"999\\\\u00b7TLG\", \"Slogan embossed on plate\"], [\"South Australia\", \"black/white\", \"Snnn\\\\u00b7aaa\", \"SOUTH AUSTRALIA\", \"S000\\\\u00b7AZD\", \"No slogan on current series\"], [\"Victoria\", \"blue/white\", \"aaa\\\\u00b7nnn\", \"VICTORIA - THE PLACE TO BE\", \"ZZZ\\\\u00b7562\", \"Current series will be exhausted this year\"]], \"name\": \"table_1000181_1\", \"page_title\": NaN, \"section_title\": NaN, \"caption\": NaN, \"page_id\": NaN, \"id\": \"1-1000181-1\"}'}\n"
          ]
        }
      ],
      "source": [
        "# --- Load main data files (.jsonl) and table schemas (.tables.jsonl) ---\n",
        "\n",
        "\"\"\"\n",
        "Loading the local jsonl files\n",
        "dev -> Validation\n",
        "train -> train\n",
        "\n",
        "The dev and train json files have a table_id key so we know which table was referenced and the table json has all the headers page titles, rows and so on\n",
        "\"\"\"\n",
        "df_main_train = pd.read_json(f\"{LOCAL_DATA_DIR}/train.jsonl\", lines=True)\n",
        "df_main_dev = pd.read_json(f\"{LOCAL_DATA_DIR}/dev.jsonl\", lines=True)\n",
        "df_table_train = pd.read_json(f\"{LOCAL_DATA_DIR}/train.tables.jsonl\", lines=True)\n",
        "df_table_dev = pd.read_json(f\"{LOCAL_DATA_DIR}/dev.tables.jsonl\", lines=True)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Create dictionary with ID as index and all of the other table info as key value pairs for this dict\n",
        "e.g\n",
        "\n",
        "{\n",
        "    # TABLE ID\n",
        "    \"1-1000181-1\": {\n",
        "\n",
        "        # COLUMN NAMES ARE INNER VALUES\n",
        "        \"header\": [\"State/territory\", \"Text/background colour\", \"Format\", \"Current slogan\", \"Current series\", \"Notes\"],\n",
        "        \"types\": [\"text\", \"text\", \"text\", \"text\", \"text\", \"text\"],\n",
        "        \"rows\": [\n",
        "            [\"Australian Capital Territory\", \"blue/white\", \"Yaa\\u00b7nna\", ...],\n",
        "            ... # All other rows\n",
        "        ],\n",
        "        \"name\": \"table_1000181_1\"\n",
        "    }\n",
        "}\n",
        "\n",
        "Why? We want to look up the table quickly when we\n",
        "\"\"\"\n",
        "table_dict_train = df_table_train.set_index('id').T.to_dict('dict')\n",
        "table_dict_dev = df_table_dev.set_index('id').T.to_dict('dict')\n",
        "\n",
        "def enforce_sql_types(sql_dict):\n",
        "    \"\"\"\n",
        "     The third value was sometimes int, sometimes string, ...\n",
        "    \"\"\"\n",
        "    if 'conds' in sql_dict:\n",
        "        new_conds = []\n",
        "        for cond in sql_dict['conds']:\n",
        "            if len(cond) == 3:\n",
        "                # Cast the third element to string\n",
        "                cond[2] = str(cond[2])\n",
        "            new_conds.append(cond)\n",
        "        sql_dict['conds'] = new_conds\n",
        "    return sql_dict\n",
        "\n",
        "def restructure_table(row):\n",
        "    \"\"\"\n",
        "     Make sure the merged table is well formed\n",
        "    \"\"\"\n",
        "    table_info = row['table']\n",
        "    # Handle NaN/missing values from map operation\n",
        "    if pd.isna(table_info) or isinstance(table_info, float):\n",
        "         table_info = {'header': [], 'types': [], 'rows': [], 'id': row['table_id']}\n",
        "    else:\n",
        "         # Ensure the ID is present in the table info dictionary\n",
        "         table_info['id'] = row['table_id']\n",
        "    return table_info\n",
        "\n",
        "def merge_and_serialize(df_main, table_dict, is_train_subset=False):\n",
        "    if is_train_subset:\n",
        "        df_subset = df_main.head(2000).copy()\n",
        "    else:\n",
        "        df_subset = df_main.copy()\n",
        "\n",
        "    # Merge the table data based on the table id\n",
        "    df_subset['table'] = df_subset['table_id'].map(table_dict)\n",
        "    df_subset['table'] = df_subset.apply(restructure_table, axis=1)\n",
        "\n",
        "    # make sure the sql part has strings in the conditions.\n",
        "    df_subset['sql'] = df_subset['sql'].apply(enforce_sql_types)\n",
        "\n",
        "    # make sure these columns are strings again not json.\n",
        "    df_subset['sql'] = df_subset['sql'].apply(json.dumps)\n",
        "    df_subset['table'] = df_subset['table'].apply(json.dumps)\n",
        "\n",
        "    # creates HF Dataset object.\n",
        "    return Dataset.from_pandas(df_subset.drop(columns=['table_id']), features=WIKISQL_FEATURES)\n",
        "\n",
        "train_dataset = merge_and_serialize(df_main_train, table_dict_train, is_train_subset=True)\n",
        "validation_dataset = merge_and_serialize(df_main_dev, table_dict_dev)\n",
        "\n",
        "# The final dataset is the subsetted train_dataset\n",
        "dataset = train_dataset\n",
        "\n",
        "print(f\"Data loading and preparation complete. Training subset size: {len(dataset)}\")\n",
        "print(\"First example:\")\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "def setup_sqlite_db_raw(table_dict, db_path):\n",
        "    if os.path.exists(db_path):\n",
        "        # Force close connection to release file lock if it exists\n",
        "        try: training_conn.close()\n",
        "        except: pass\n",
        "        os.remove(db_path)\n",
        "\n",
        "    conn = sqlite3.connect(db_path, timeout=30)\n",
        "    conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
        "    print(f\"Building SQLite database with RAW headers...\")\n",
        "\n",
        "    for table_id, info in table_dict.items():\n",
        "        safe_table_name = f\"table_{table_id.replace('-', '_')}\"\n",
        "        headers = info['header']\n",
        "\n",
        "        # Handle exact duplicate headers\n",
        "        final_headers = []\n",
        "        seen = {}\n",
        "        for h in headers:\n",
        "            h_str = str(h)\n",
        "            if h_str in seen:\n",
        "                seen[h_str] += 1\n",
        "                h_str = f\"{h_str}_{seen[h_str]}\"\n",
        "            else:\n",
        "                seen[h_str] = 1\n",
        "            final_headers.append(h_str)\n",
        "\n",
        "        cols_definition = \", \".join([f'\"{name}\" TEXT' for name in final_headers])\n",
        "\n",
        "        try:\n",
        "            conn.execute(f'CREATE TABLE \"{safe_table_name}\" ({cols_definition});')\n",
        "            placeholders = \", \".join([\"?\"] * len(final_headers))\n",
        "            conn.executemany(f'INSERT INTO \"{safe_table_name}\" VALUES ({placeholders});', info['rows'])\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "training_conn = setup_sqlite_db_raw(table_dict_train, \"wikisql_training.db\")"
      ],
      "metadata": {
        "id": "4w1NQvTp2h5p",
        "outputId": "0f85ce6a-840c-412f-ccad-9fead0542c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4w1NQvTp2h5p",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building SQLite database with RAW headers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_table_id = list(table_dict_train.keys())[0]\n",
        "safe_name = f\"table_{sample_table_id.replace('-', '_')}\"\n",
        "\n",
        "print(f\"Testing Query on: {safe_name}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "try:\n",
        "    query = f'SELECT * FROM \"{safe_name}\" LIMIT 2'\n",
        "    df_test = pd.read_sql_query(query, training_conn)\n",
        "\n",
        "    print(\"Successfully retrieved data:\")\n",
        "    display(df_test)\n",
        "\n",
        "    print(\"\\nRaw Column Names in DB:\")\n",
        "    print(df_test.columns.tolist())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Query failed: {e}\")"
      ],
      "metadata": {
        "id": "jvmyl9_25goW",
        "outputId": "64cb0cbd-86f5-4c93-8ea1-4a2a89b82d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "id": "jvmyl9_25goW",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Query on: table_1_1000181_1\n",
            "------------------------------\n",
            "Successfully retrieved data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                State/territory Text/background colour    Format  \\\n",
              "0  Australian Capital Territory             blue/white   Yaa·nna   \n",
              "1               New South Wales           black/yellow  aa·nn·aa   \n",
              "\n",
              "                        Current slogan Current series  \\\n",
              "0  ACT · CELEBRATION OF A CENTURY 2013        YIL·00A   \n",
              "1                      NEW SOUTH WALES       BX·99·HI   \n",
              "\n",
              "                           Notes  \n",
              "0  Slogan screenprinted on plate  \n",
              "1    No slogan on current series  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1defc2a4-9fa7-4315-a024-2a71f6cc2852\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State/territory</th>\n",
              "      <th>Text/background colour</th>\n",
              "      <th>Format</th>\n",
              "      <th>Current slogan</th>\n",
              "      <th>Current series</th>\n",
              "      <th>Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australian Capital Territory</td>\n",
              "      <td>blue/white</td>\n",
              "      <td>Yaa·nna</td>\n",
              "      <td>ACT · CELEBRATION OF A CENTURY 2013</td>\n",
              "      <td>YIL·00A</td>\n",
              "      <td>Slogan screenprinted on plate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New South Wales</td>\n",
              "      <td>black/yellow</td>\n",
              "      <td>aa·nn·aa</td>\n",
              "      <td>NEW SOUTH WALES</td>\n",
              "      <td>BX·99·HI</td>\n",
              "      <td>No slogan on current series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1defc2a4-9fa7-4315-a024-2a71f6cc2852')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1defc2a4-9fa7-4315-a024-2a71f6cc2852 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1defc2a4-9fa7-4315-a024-2a71f6cc2852');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68ecca2a-5bc6-451e-b284-75a7624f148f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68ecca2a-5bc6-451e-b284-75a7624f148f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68ecca2a-5bc6-451e-b284-75a7624f148f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_60c4030d-bd38-4f23-8c1b-c07167caf78b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60c4030d-bd38-4f23-8c1b-c07167caf78b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"State/territory\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"New South Wales\",\n          \"Australian Capital Territory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text/background colour\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"black/yellow\",\n          \"blue/white\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Format\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"aa\\u00b7nn\\u00b7aa\",\n          \"Yaa\\u00b7nna\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Current slogan\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NEW SOUTH WALES\",\n          \"ACT \\u00b7 CELEBRATION OF A CENTURY 2013\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Current series\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BX\\u00b799\\u00b7HI\",\n          \"YIL\\u00b700A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Notes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No slogan on current series\",\n          \"Slogan screenprinted on plate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw Column Names in DB:\n",
            "['State/territory', 'Text/background colour', 'Format', 'Current slogan', 'Current series', 'Notes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c4b245ed",
      "metadata": {
        "id": "c4b245ed",
        "outputId": "8871b9c8-a45a-46de-c737-029e93fc0b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'phase': 1,\n",
              " 'question': 'Tell me what the notes are for South Australia ',\n",
              " 'sql': '{\"sel\": 5, \"conds\": [[3, 0, \"SOUTH AUSTRALIA\"]], \"agg\": 0}',\n",
              " 'table': '{\"header\": [\"State/territory\", \"Text/background colour\", \"Format\", \"Current slogan\", \"Current series\", \"Notes\"], \"types\": [\"text\", \"text\", \"text\", \"text\", \"text\", \"text\"], \"rows\": [[\"Australian Capital Territory\", \"blue/white\", \"Yaa\\\\u00b7nna\", \"ACT \\\\u00b7 CELEBRATION OF A CENTURY 2013\", \"YIL\\\\u00b700A\", \"Slogan screenprinted on plate\"], [\"New South Wales\", \"black/yellow\", \"aa\\\\u00b7nn\\\\u00b7aa\", \"NEW SOUTH WALES\", \"BX\\\\u00b799\\\\u00b7HI\", \"No slogan on current series\"], [\"New South Wales\", \"black/white\", \"aaa\\\\u00b7nna\", \"NSW\", \"CPX\\\\u00b712A\", \"Optional white slimline series\"], [\"Northern Territory\", \"ochre/white\", \"Ca\\\\u00b7nn\\\\u00b7aa\", \"NT \\\\u00b7 OUTBACK AUSTRALIA\", \"CB\\\\u00b706\\\\u00b7ZZ\", \"New series began in June 2011\"], [\"Queensland\", \"maroon/white\", \"nnn\\\\u00b7aaa\", \"QUEENSLAND \\\\u00b7 SUNSHINE STATE\", \"999\\\\u00b7TLG\", \"Slogan embossed on plate\"], [\"South Australia\", \"black/white\", \"Snnn\\\\u00b7aaa\", \"SOUTH AUSTRALIA\", \"S000\\\\u00b7AZD\", \"No slogan on current series\"], [\"Victoria\", \"blue/white\", \"aaa\\\\u00b7nnn\", \"VICTORIA - THE PLACE TO BE\", \"ZZZ\\\\u00b7562\", \"Current series will be exhausted this year\"]], \"name\": \"table_1000181_1\", \"page_title\": NaN, \"section_title\": NaN, \"caption\": NaN, \"page_id\": NaN, \"id\": \"1-1000181-1\"}',\n",
              " 'prompt': '[GOLD_SQL]{\"sel\": 5, \"conds\": [[3, 0, \"SOUTH AUSTRALIA\"]], \"agg\": 0}[/GOLD_SQL]\\n[TABLE_ID]1-1000181-1[/TABLE_ID]\\nGenerate a SQL query to answer the question based on the table schema.\\nSchema: [\\'State/territory\\', \\'Text/background colour\\', \\'Format\\', \\'Current slogan\\', \\'Current series\\', \\'Notes\\']\\nQuestion: Tell me what the notes are for South Australia \\nWrap your answer in <sql> tags.\\nAnswer:'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sqlglot\n",
        "\n",
        "def format_wikisql_with_gold_target(example):\n",
        "    \"\"\"Formats the prompt with hidden metadata for the reward functions.\"\"\"\n",
        "    table_dict = json.loads(example[\"table\"])\n",
        "    table_header = table_dict[\"header\"]\n",
        "    question = example[\"question\"]\n",
        "    gold_sql = example[\"sql\"] # This is the WikiSQL JSON logic\n",
        "    table_id = table_dict[\"id\"]\n",
        "\n",
        "    prompt = (\n",
        "        f\"[GOLD_SQL]{gold_sql}[/GOLD_SQL]\\n\"\n",
        "        f\"[TABLE_ID]{table_id}[/TABLE_ID]\\n\"\n",
        "        f\"Generate a SQL query to answer the question based on the table schema.\\n\"\n",
        "        f\"Schema: {table_header}\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Wrap your answer in <sql> tags.\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "    return {\"prompt\": prompt}\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Weight: 2.0\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for completion in completions:\n",
        "        text = completion.strip()\n",
        "        if text.startswith(\"<sql>\") and text.endswith(\"</sql>\"):\n",
        "            # Penalize if it repeats the question or table inside the tags\n",
        "            if any(x in text for x in [\"Question:\", \"Table:\", \"Schema:\"]):\n",
        "                rewards.append(0.5)\n",
        "            else:\n",
        "                rewards.append(2.0)\n",
        "        else:\n",
        "            rewards.append(0.0)\n",
        "    return rewards\n",
        "\n",
        "def execution_and_syntax_combo_reward(prompts, completions, **kwargs):\n",
        "    \"\"\"\n",
        "    Weight: 8.0\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    global training_conn\n",
        "\n",
        "    for prompt, completion in zip(prompts, completions):\n",
        "        score = 0.0\n",
        "        try:\n",
        "\n",
        "            gt_json = json.loads(prompt.split(\"[GOLD_SQL]\")[1].split(\"[/GOLD_SQL]\")[0])\n",
        "            schema_cols = eval(prompt.split(\"Schema: \")[1].split(\"\\nQuestion\")[0])\n",
        "            table_id = prompt.split(\"[TABLE_ID]\")[1].split(\"[/TABLE_ID]\")[0]\n",
        "\n",
        "            if \"<sql>\" not in completion or \"</sql>\" not in completion:\n",
        "                rewards.append(0.0)\n",
        "                continue\n",
        "\n",
        "            gen_sql = completion.split(\"<sql>\")[1].split(\"</sql>\")[0].strip()\n",
        "\n",
        "            if \"*\" in gen_sql:\n",
        "                rewards.append(-2.0)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                sqlglot.parse(gen_sql, read=\"sqlite\")\n",
        "                score += 3.0\n",
        "            except:\n",
        "                rewards.append(-1.0) # Penalty for broken SQL\n",
        "                continue\n",
        "\n",
        "\n",
        "            gold_sql_str = gold_json_to_sql_string(gt_json, table_id, schema_cols)\n",
        "            gold_res = set(training_conn.execute(gold_sql_str).fetchall())\n",
        "\n",
        "            try:\n",
        "                gen_res = set(training_conn.execute(gen_sql).fetchall())\n",
        "\n",
        "                if gen_res == gold_res:\n",
        "                    score += 5.\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                score -= 2.0 # Penalty if the SQL is valid syntax but fails on THIS table\n",
        "            rewards.append(max(0.0, score)) # Ensure no negative total scores for valid attempts\n",
        "\n",
        "\n",
        "        except Exception:\n",
        "            rewards.append(0.0)\n",
        "\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "V_TK6jbkPdXV"
      },
      "id": "V_TK6jbkPdXV",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(format_wikisql_with_gold_target)"
      ],
      "metadata": {
        "id": "0pnyZStUImid"
      },
      "id": "0pnyZStUImid",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf242c9",
      "metadata": {
        "id": "faf242c9",
        "outputId": "a8a8c077-a0d3-4a20-ad7b-f03d3f21207f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:192: FutureWarning: The `max_prompt_length` argument is deprecated and will be removed in version 0.28.0. You should instead filter your dataset before training to ensure that prompts do not exceed your desired length.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GRPO Training for Text-to-SQL with full logical rewards...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='605' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 605/1000 1:43:17 < 1:07:39, 0.10 it/s, Epoch 0.60/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>-0.018100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>-0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>-0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>-0.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>-0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>-0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>-0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>-0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>-0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>-0.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>-0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>-0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>-0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>-0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>-0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>-0.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>-0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>-0.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>-0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>-0.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>-0.006100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Load Tokenizer (Keep this, as it's needed for the AutoModelForCausalLM and data prep)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load Model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# LoRA Configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    lora_dropout=0.05,\n",
        ")\n",
        "\n",
        "# GRPO Config\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    learning_rate=1e-5,\n",
        "    bf16=False, # Disabled cause of Collab\n",
        "    fp16=True,\n",
        "    tf32=False,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_generations=4,\n",
        "    max_prompt_length=MAX_PROMPT_LENGTH,\n",
        "    max_completion_length=MAX_COMPLETION_LENGTH,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    report_to=\"none\",\n",
        "    use_vllm=False\n",
        ")\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    reward_funcs=[\n",
        "        strict_format_reward_func,\n",
        "        execution_and_syntax_combo_reward\n",
        "    ],\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config\n",
        ")\n",
        "\n",
        "print(\"Starting GRPO Training for Text-to-SQL with full logical rewards...\")\n",
        "try:\n",
        "    trainer.train()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user. Proceeding to final save...\")\n",
        "\n",
        "# Save the final adapter\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "print(f\"Training complete. Model saved to {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "97a50eb1",
      "metadata": {
        "id": "97a50eb1",
        "outputId": "14268d80-560e-4ddd-bfc8-8da223e7b65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "d49f390647e04273ae171020f42bceae",
            "915c8206a12844d5852b0990c5ae8437",
            "734c00835ef14108b736d00dcda96531",
            "721ac2599ca74164bb3916e7d51a28c6",
            "35bdf8a2fc9f4ea19859d4fa201e633c",
            "7941eeec58b3450bb2591aa830dd439d",
            "dc67f0f9822b4f9dbb650f4afcba4611",
            "807f200f42624c16a01fda21b3359b9c",
            "adb482db60d14b428712ce747c709338",
            "4d5be9ecb75a439ca40517d764e02f1b",
            "24f2dd9dae464832a2f90f7add50d122"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading Tokenizer and Base Model...\n",
            "2. Loading and Merging LoRA Adapter...\n",
            "✅ Model adapter merged and ready for inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d49f390647e04273ae171020f42bceae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST CASE ---\n",
            "Question: How many schools did player number 3 play at?\n",
            "Ground Truth SQL: {'sel': 5, 'conds': [[1, 0, '3']], 'agg': 3}\n",
            "--- Generating Query ---\n",
            "\n",
            "--- RESULTS ---\n",
            "Generated Raw Text: <sql>SELECT * FROM table</sql>\n",
            "Extracted SQL: SELECT * FROM table\n",
            "\n",
            "--- FINAL VERDICT ---\n",
            "SUCCESS: The model generated syntactically plausible SQL.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, Features, Value\n",
        "import os # <-- IMPORTED OS FOR PATH JOINING\n",
        "\n",
        "# --- FIX 1: UPDATED OUTPUT_DIR to E: DRIVE ---\n",
        "# Assuming the adapter was saved here after the GRPO training run.\n",
        "OUTPUT_DIR = \"/granite-grpo-wikisql\"\n",
        "MAX_PROMPT_LENGTH = 512\n",
        "MAX_COMPLETION_LENGTH = 128\n",
        "\n",
        "# --- FIX 2: Using os.path.join for robust local data access ---\n",
        "# This ensures the script finds the data files regardless of where the script is run from.\n",
        "LOCAL_DATA_DIR = os.path.join(os.getcwd(), \"data\")\n",
        "# --- Utility Functions (Must match the ones used in pre-processing) ---\n",
        "def format_wikisql(example):\n",
        "    \"\"\"Formats the input prompt for the model.\"\"\"\n",
        "    table_dict = json.loads(example[\"table\"])\n",
        "    table_header = table_dict[\"header\"]\n",
        "    question = example[\"question\"]\n",
        "\n",
        "    prompt = (\n",
        "        f\"Generate a SQL query to answer the question based on the table schema.\\n\"\n",
        "        f\"Schema: {table_header}\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Wrap your answer in <sql> tags. For example: <sql>SELECT * FROM table</sql>.\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "    return {\"prompt\": prompt}\n",
        "\n",
        "def get_validation_data():\n",
        "    \"\"\"Simplified data loading for the dev set.\"\"\"\n",
        "    df_main_dev = pd.read_json(f\"{LOCAL_DATA_DIR}/dev.jsonl\", lines=True)\n",
        "    df_table_dev = pd.read_json(f\"{LOCAL_DATA_DIR}/dev.tables.jsonl\", lines=True)\n",
        "    table_dict_dev = df_table_dev.set_index('id').T.to_dict('dict')\n",
        "\n",
        "    # We need the full merge and serialize here, but for brevity, we assume\n",
        "    # a function similar to merge_and_serialize was used to generate this.\n",
        "\n",
        "    # For a quick test, we will just merge and serialize the first 10 dev samples:\n",
        "    df_subset = df_main_dev.head(10).copy()\n",
        "    df_subset['table'] = df_subset['table_id'].map(table_dict_dev)\n",
        "    # NOTE: In a full script, you would include restructure_table and enforce_sql_types here\n",
        "\n",
        "    # Simple serialization for demonstration:\n",
        "    df_subset['sql'] = df_subset['sql'].apply(json.dumps)\n",
        "    df_subset['table'] = df_subset['table'].apply(json.dumps)\n",
        "\n",
        "    dataset = Dataset.from_pandas(df_subset.drop(columns=['table_id']), features=WIKISQL_FEATURES)\n",
        "    return dataset.map(format_wikisql)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Model Loading and Inference\n",
        "# ==========================================\n",
        "print(\"1. Loading Tokenizer and Base Model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"2. Loading and Merging LoRA Adapter...\")\n",
        "model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
        "model = model.merge_and_unload()\n",
        "model.eval()\n",
        "print(\"✅ Model adapter merged and ready for inference.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. Testing Inference\n",
        "# ==========================================\n",
        "validation_dataset = get_validation_data()\n",
        "test_sample = validation_dataset[1] # Use the second example\n",
        "\n",
        "prompt = test_sample[\"prompt\"]\n",
        "ground_truth_sql = json.loads(test_sample[\"sql\"]) # Deserialize for comparison\n",
        "\n",
        "print(\"\\n--- TEST CASE ---\")\n",
        "print(f\"Question: {test_sample['question']}\")\n",
        "print(f\"Ground Truth SQL: {ground_truth_sql}\")\n",
        "print(\"--- Generating Query ---\")\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Generate the completion\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=MAX_COMPLETION_LENGTH,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "# Decode the output, stripping the input prompt\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "generated_completion = generated_text[len(prompt):].strip()\n",
        "\n",
        "# --- Post-Processing ---\n",
        "try:\n",
        "    # Extract the SQL from between the tags (as done in the reward functions)\n",
        "    generated_sql = generated_completion.split(\"<sql>\")[1].split(\"</sql>\")[0].strip()\n",
        "except IndexError:\n",
        "    generated_sql = \"Extraction Failed (Tags Missing)\"\n",
        "\n",
        "print(\"\\n--- RESULTS ---\")\n",
        "print(f\"Generated Raw Text: {generated_completion}\")\n",
        "print(f\"Extracted SQL: {generated_sql}\")\n",
        "print(\"\\n--- FINAL VERDICT ---\")\n",
        "\n",
        "# Simple comparison for demonstration\n",
        "if generated_sql and generated_sql != \"Extraction Failed (Tags Missing)\":\n",
        "    print(\"SUCCESS: The model generated syntactically plausible SQL.\")\n",
        "else:\n",
        "    print(\"FAILURE: The model failed to adhere to the required format.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "15960d11",
      "metadata": {
        "id": "15960d11",
        "outputId": "c2c9a25e-41e2-4d70-d753-27a3f1594dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST CASE 2 ---\n",
            "Question: What position does the player who played for butler cc (ks) play?\n",
            "Ground Truth SQL: {'sel': 3, 'conds': [[5, 0, 'Butler CC (KS)']], 'agg': 0}\n",
            "--- Generating Query ---\n",
            "\n",
            "--- RESULTS ---\n",
            "Extracted SQL: Extraction Failed (Tags Missing)\n"
          ]
        }
      ],
      "source": [
        "test_sample_1 = validation_dataset[0]\n",
        "\n",
        "prompt = test_sample_1[\"prompt\"]\n",
        "ground_truth_sql = json.loads(test_sample_1[\"sql\"])\n",
        "\n",
        "print(\"\\n--- TEST CASE 2 ---\")\n",
        "print(f\"Question: {test_sample_1['question']}\")\n",
        "print(f\"Ground Truth SQL: {ground_truth_sql}\")\n",
        "print(\"--- Generating Query ---\")\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Generate the completion\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=MAX_COMPLETION_LENGTH,\n",
        "        do_sample=False, # Use greedy decoding for predictable results\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "generated_completion = generated_text[len(prompt):].strip()\n",
        "\n",
        "# --- Post-Processing ---\n",
        "try:\n",
        "    generated_sql = generated_completion.split(\"<sql>\")[1].split(\"</sql>\")[0].strip()\n",
        "except IndexError:\n",
        "    generated_sql = \"Extraction Failed (Tags Missing)\"\n",
        "\n",
        "print(\"\\n--- RESULTS ---\")\n",
        "print(f\"Extracted SQL: {generated_sql}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4c3ffdaa",
      "metadata": {
        "id": "4c3ffdaa",
        "outputId": "76e9394b-11b2-4018-a1c5-b0bbb336faea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST CASE 3 ---\n",
            "Question: Who are all of the players on the Westchester High School club team?\n",
            "Ground Truth SQL: {'sel': 0, 'conds': [[5, 0, 'Westchester High School']], 'agg': 0}\n",
            "--- Generating Query ---\n",
            "\n",
            "--- RESULTS ---\n",
            "Extracted SQL: SELECT * FROM table\n"
          ]
        }
      ],
      "source": [
        "test_sample_5 = validation_dataset[5]\n",
        "\n",
        "prompt = test_sample_5[\"prompt\"]\n",
        "ground_truth_sql = json.loads(test_sample_5[\"sql\"])\n",
        "\n",
        "print(\"\\n--- TEST CASE 3 ---\")\n",
        "print(f\"Question: {test_sample_5['question']}\")\n",
        "print(f\"Ground Truth SQL: {ground_truth_sql}\")\n",
        "print(\"--- Generating Query ---\")\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Generate the completion\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=MAX_COMPLETION_LENGTH,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "generated_completion = generated_text[len(prompt):].strip()\n",
        "\n",
        "# --- Post-Processing ---\n",
        "try:\n",
        "    generated_sql = generated_completion.split(\"<sql>\")[1].split(\"</sql>\")[0].strip()\n",
        "except IndexError:\n",
        "    generated_sql = \"Extraction Failed (Tags Missing)\"\n",
        "\n",
        "print(\"\\n--- RESULTS ---\")\n",
        "print(f\"Extracted SQL: {generated_sql}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_model_output(model, tokenizer, question, schema):\n",
        "    # 1. Prepare the prompt (No GOLD_SQL tags here, just like real life)\n",
        "    prompt = (\n",
        "        f\"Generate a SQL query to answer the question based on the table schema.\\n\"\n",
        "        f\"Schema: {schema}\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Wrap your answer in <sql> tags. For example: <sql>SELECT * FROM table</sql>.\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    # 2. Tokenize\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # 3. Generate\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=128,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # 4. Decode EVERYTHING (skip_special_tokens=False to see EOS tags)\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # 5. Extract only the new part (after the prompt)\n",
        "    response_part = full_text.split(\"Answer:\")[1]\n",
        "\n",
        "    return response_part\n",
        "\n",
        "# --- RUN TEST ---\n",
        "test_q = \"How many schools did player number 3 play at?\"\n",
        "test_s = \"['ID', 'Player', 'No.', 'School/Club Team', 'Years', 'Notes']\"\n",
        "\n",
        "raw_response = get_raw_model_output(model, tokenizer, test_q, test_s)\n",
        "\n",
        "print(\"--- RAW MODEL OUTPUT ---\")\n",
        "print(raw_response)\n",
        "print(\"------------------------\")"
      ],
      "metadata": {
        "id": "aCiwgUnLLwVn",
        "outputId": "84980615-3a64-4577-c242-c84b1731ac04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aCiwgUnLLwVn",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW MODEL OUTPUT ---\n",
            " <sql>SELECT * FROM table</sql><|end_of_text|>\n",
            "------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d49f390647e04273ae171020f42bceae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_915c8206a12844d5852b0990c5ae8437",
              "IPY_MODEL_734c00835ef14108b736d00dcda96531",
              "IPY_MODEL_721ac2599ca74164bb3916e7d51a28c6"
            ],
            "layout": "IPY_MODEL_35bdf8a2fc9f4ea19859d4fa201e633c"
          }
        },
        "915c8206a12844d5852b0990c5ae8437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7941eeec58b3450bb2591aa830dd439d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc67f0f9822b4f9dbb650f4afcba4611",
            "value": "Map: 100%"
          }
        },
        "734c00835ef14108b736d00dcda96531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_807f200f42624c16a01fda21b3359b9c",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adb482db60d14b428712ce747c709338",
            "value": 10
          }
        },
        "721ac2599ca74164bb3916e7d51a28c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5be9ecb75a439ca40517d764e02f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_24f2dd9dae464832a2f90f7add50d122",
            "value": " 10/10 [00:00&lt;00:00, 489.78 examples/s]"
          }
        },
        "35bdf8a2fc9f4ea19859d4fa201e633c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7941eeec58b3450bb2591aa830dd439d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc67f0f9822b4f9dbb650f4afcba4611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "807f200f42624c16a01fda21b3359b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb482db60d14b428712ce747c709338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d5be9ecb75a439ca40517d764e02f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f2dd9dae464832a2f90f7add50d122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}